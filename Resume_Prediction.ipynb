{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a152c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (0.2.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain) (8.4.1)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain) (0.2.7)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain) (2.7.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain) (0.1.77)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d16ee5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (0.2.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-community) (6.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-community) (1.23.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.5 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-community) (0.2.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-community) (8.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-community) (1.4.39)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-community) (0.1.77)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-community) (2.28.1)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-community) (0.2.7)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.5->langchain-community) (2.7.4)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.5->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.7->langchain-community) (24.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.7->langchain-community) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (2.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain-community) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (0.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08300933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting poppler-utils\n",
      "  Downloading poppler_utils-0.1.0-py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: Click>=7.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from poppler-utils) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from Click>=7.0->poppler-utils) (0.4.6)\n",
      "Installing collected packages: poppler-utils\n",
      "Successfully installed poppler-utils-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "988b9cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eefad1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured[pdf] in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (0.14.6)\n",
      "Collecting unstructured[pdf]\n",
      "  Downloading unstructured-0.14.9-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 6.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (4.12.2)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (3.9.3)\n",
      "Requirement already satisfied: chardet in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (4.0.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (4.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (4.64.1)\n",
      "Requirement already satisfied: python-iso639 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (2024.4.27)\n",
      "Requirement already satisfied: filetype in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (1.2.0)\n",
      "Requirement already satisfied: unstructured-client in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (0.8.1)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (1.23.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (0.6.7)\n",
      "Requirement already satisfied: requests in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (4.11.1)\n",
      "Requirement already satisfied: backoff in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (2.2.1)\n",
      "Requirement already satisfied: langdetect in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (1.0.9)\n",
      "Requirement already satisfied: tabulate in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (0.8.10)\n",
      "Requirement already satisfied: emoji in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (2.12.1)\n",
      "Requirement already satisfied: python-magic in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (0.4.27)\n",
      "Requirement already satisfied: nltk in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (3.7)\n",
      "Requirement already satisfied: wrapt in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured[pdf]) (1.14.1)\n",
      "Collecting unstructured-inference==0.7.36\n",
      "  Downloading unstructured_inference-0.7.36-py3-none-any.whl (56 kB)\n",
      "     -------------------------------------- 56.4/56.4 kB 592.2 kB/s eta 0:00:00\n",
      "Collecting onnx\n",
      "  Using cached onnx-1.16.1-cp310-cp310-win_amd64.whl (14.4 MB)\n",
      "Collecting google-cloud-vision\n",
      "  Using cached google_cloud_vision-3.7.2-py2.py3-none-any.whl (459 kB)\n",
      "Collecting unstructured.pytesseract>=0.3.12\n",
      "  Using cached unstructured.pytesseract-0.3.12-py3-none-any.whl (14 kB)\n",
      "Collecting effdet\n",
      "  Using cached effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "Collecting pikepdf\n",
      "  Using cached pikepdf-9.0.0-cp310-cp310-win_amd64.whl (3.5 MB)\n",
      "Collecting pillow-heif\n",
      "  Using cached pillow_heif-0.16.0-cp310-cp310-win_amd64.whl (8.2 MB)\n",
      "Collecting pytesseract\n",
      "  Using cached pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Collecting pdfminer.six\n",
      "  Using cached pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "Collecting pdf2image\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Collecting pypdf\n",
      "  Using cached pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "Collecting transformers>=4.25.1\n",
      "  Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
      "     ---------------------------------------- 9.3/9.3 MB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (0.10.1)\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.7-py3-none-any.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 11.3 MB/s eta 0:00:00\n",
      "Collecting opencv-python!=4.7.0.68\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "     ---------------------------------------- 38.8/38.8 MB 4.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (1.12.1)\n",
      "Collecting layoutparser\n",
      "  Using cached layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
      "Collecting python-multipart\n",
      "  Using cached python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (3.7.0)\n",
      "Collecting onnxruntime>=1.17.0\n",
      "  Downloading onnxruntime-1.18.1-cp310-cp310-win_amd64.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (9.4.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (24.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from beautifulsoup4->unstructured[pdf]) (2.3.2.post1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from dataclasses-json->unstructured[pdf]) (3.21.3)\n",
      "Collecting pycocotools>=2.0.2\n",
      "  Using cached pycocotools-2.0.8-cp310-cp310-win_amd64.whl (84 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.18.1-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "Collecting omegaconf>=2.0\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "     -------------------------------------- 50.1/50.1 kB 847.7 kB/s eta 0:00:00\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5\n",
      "  Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1\n",
      "  Using cached google_auth-2.30.0-py2.py3-none-any.whl (193 kB)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "     -------------------------------------- 139.4/139.4 kB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from langdetect->unstructured[pdf]) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from nltk->unstructured[pdf]) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from nltk->unstructured[pdf]) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from nltk->unstructured[pdf]) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from pdfminer.six->unstructured[pdf]) (2.1.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from pdfminer.six->unstructured[pdf]) (39.0.1)\n",
      "Collecting Deprecated\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting Pillow>=8.0.0\n",
      "  Using cached pillow-10.3.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests->unstructured[pdf]) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests->unstructured[pdf]) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests->unstructured[pdf]) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from tqdm->unstructured[pdf]) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured[pdf]) (2.8.2)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured[pdf]) (1.0.6)\n",
      "Requirement already satisfied: marshmallow-enum>=1.5.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured[pdf]) (1.5.1)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured[pdf]) (3.0.9)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured[pdf]) (0.4.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (1.15.1)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "     -------------------------------------- 220.0/220.0 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Using cached grpcio_status-1.64.1-py3-none-any.whl (14 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2\n",
      "  Using cached grpcio-1.64.1-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.2.8)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (6.0)\n",
      "Collecting flatbuffers\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (1.11.1)\n",
      "Collecting coloredlogs\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (1.4.4)\n",
      "Collecting safetensors\n",
      "  Using cached safetensors-0.4.3-cp310-none-win_amd64.whl (287 kB)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Using cached tokenizers-0.19.1-cp310-none-win_amd64.whl (2.2 MB)\n",
      "Collecting huggingface-hub\n",
      "  Using cached huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference==0.7.36->unstructured[pdf]) (3.9.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "     -------------------------------------- 177.6/177.6 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (1.5.3)\n",
      "Collecting pdfplumber\n",
      "  Using cached pdfplumber-0.11.1-py3-none-any.whl (57 kB)\n",
      "Collecting iopath\n",
      "  Using cached iopath-0.1.10-py3-none-any.whl\n",
      "Requirement already satisfied: scipy in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (1.10.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.3.1-cp310-cp310-win_amd64.whl (159.8 MB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (2.8.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (2.21)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Using cached grpcio_status-1.64.0-py3-none-any.whl (14 kB)\n",
      "  Using cached grpcio_status-1.63.0-py3-none-any.whl (14 kB)\n",
      "  Using cached grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Collecting intel-openmp==2021.*\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Collecting tbb==2021.*\n",
      "  Downloading tbb-2021.13.0-py3-none-win_amd64.whl (286 kB)\n",
      "     -------------------------------------- 286.9/286.9 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.4.8)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.10.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from jinja2->torch->unstructured-inference==0.7.36->unstructured[pdf]) (2.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from pandas->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (2022.7)\n",
      "Collecting pypdfium2>=4.18.0\n",
      "  Using cached pypdfium2-4.30.0-py3-none-win_amd64.whl (2.9 MB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (1.2.1)\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from portalocker->iopath->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (305.1)\n",
      "Installing collected packages: tbb, pyreadline3, intel-openmp, flatbuffers, antlr4-python3-runtime, safetensors, rsa, python-multipart, pypdfium2, pypdf, protobuf, portalocker, Pillow, opencv-python, omegaconf, mkl, humanfriendly, grpcio, fsspec, Deprecated, cachetools, unstructured.pytesseract, torch, pytesseract, proto-plus, pillow-heif, pikepdf, pdf2image, onnx, iopath, huggingface-hub, googleapis-common-protos, google-auth, coloredlogs, torchvision, tokenizers, pycocotools, pdfminer.six, onnxruntime, grpcio-status, google-api-core, unstructured, transformers, timm, pdfplumber, layoutparser, google-cloud-vision, effdet, unstructured-inference\n",
      "  Attempting uninstall: tbb\n",
      "    Found existing installation: TBB 0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade \"unstructured[pdf]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d384b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfminer.six\n",
      "  Using cached pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from pdfminer.six) (39.0.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.1.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Installing collected packages: pdfminer.six\n",
      "Successfully installed pdfminer.six-20231228\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfminer.six\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26461bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "     -------------------------------------- 227.1/227.1 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Collecting transformers<5.0.0,>=4.34.0\n",
      "  Using cached transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.23.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.10.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: requests in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Using cached safetensors-0.4.3-cp310-none-win_amd64.whl (287 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chnn2\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.14)\n",
      "Installing collected packages: safetensors, transformers, sentence-transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.24.0\n",
      "    Uninstalling transformers-4.24.0:\n",
      "      Successfully uninstalled transformers-4.24.0\n",
      "Successfully installed safetensors-0.4.3 sentence-transformers-3.0.1 transformers-4.42.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56265bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-ibm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef52713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chnn2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15bedcd",
   "metadata": {},
   "source": [
    "## Document loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829873a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory='C:/Users/chnn2/resumeShortlisting/files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75b8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79109b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634d04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(directory):\n",
    "  loader = DirectoryLoader(directory,show_progress=True) \n",
    "  documents = loader.load()\n",
    "  return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e812a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.96s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = load_docs(directory) \n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a0810f",
   "metadata": {},
   "source": [
    "## Splitting the documents into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d45321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c8425c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_docs(documents, chunk_size=1000, chunk_overlap=100):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8166b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=split_docs(documents,1000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "629a7693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f970cfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f553badb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='WORK EXPERIENCE Software Engineer Intern F5 Networks\\n\\nFALLON WINSLOW Software Engineer Intern\\n\\n2023 - current\\n\\nSeattle, WA Implemented a new authentication module in Python, improving system security compliance and saving an estimated $2,046 on potential breach risks Upgraded the Jenkins pipeline for continuous integration, speeding up code deployment times by three hours Developed a MySQL database schema design, improving data integrity and access speed by 39% Designed a user-friendly interface for our internal tool using Django, which increased user adoption by an extra 329 users within the ﬁrst week alone\\n\\nf.winslow@email.com (123) 456-7890 Seattle, WA LinkedIn\\n\\nEDUCATION Bachelor of Science Computer Science University of Washington\\n\\nPROJECTS CodeIt Team Member\\n\\n2019 - 2023 Seattle, WA\\n\\n2022', metadata={'source': 'C:\\\\Users\\\\chnn2\\\\resumeShortlisting\\\\files\\\\resume1.pdf'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e441e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    doc.page_content.replace(\"\\n,\",\" \").strip()\n",
    "    doc.page_content.replace(\"\\n\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75991a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WORK EXPERIENCE Software Engineer Intern F5 Networks\\n\\nFALLON WINSLOW Software Engineer Intern\\n\\n2023 - current\\n\\nSeattle, WA Implemented a new authentication module in Python, improving system security compliance and saving an estimated $2,046 on potential breach risks Upgraded the Jenkins pipeline for continuous integration, speeding up code deployment times by three hours Developed a MySQL database schema design, improving data integrity and access speed by 39% Designed a user-friendly interface for our internal tool using Django, which increased user adoption by an extra 329 users within the ﬁrst week alone\\n\\nf.winslow@email.com (123) 456-7890 Seattle, WA LinkedIn\\n\\nEDUCATION Bachelor of Science Computer Science University of Washington\\n\\nPROJECTS CodeIt Team Member\\n\\n2019 - 2023 Seattle, WA\\n\\n2022'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b3564a",
   "metadata": {},
   "source": [
    "## Analyzing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e5a0f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b87fdf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of char in chunk: \n",
      "805\n",
      "No of words in chunk: \n",
      "107\n",
      "Approx no of tokens per chunk: \n",
      "201.25\n",
      "No of char in chunk: \n",
      "753\n",
      "No of words in chunk: \n",
      "110\n",
      "Approx no of tokens per chunk: \n",
      "188.25\n",
      "No of char in chunk: \n",
      "610\n",
      "No of words in chunk: \n",
      "89\n",
      "Approx no of tokens per chunk: \n",
      "152.5\n",
      "No of char in chunk: \n",
      "990\n",
      "No of words in chunk: \n",
      "137\n",
      "Approx no of tokens per chunk: \n",
      "247.5\n",
      "No of char in chunk: \n",
      "974\n",
      "No of words in chunk: \n",
      "141\n",
      "Approx no of tokens per chunk: \n",
      "243.5\n",
      "No of char in chunk: \n",
      "553\n",
      "No of words in chunk: \n",
      "84\n",
      "Approx no of tokens per chunk: \n",
      "138.25\n",
      "No of char in chunk: \n",
      "988\n",
      "No of words in chunk: \n",
      "115\n",
      "Approx no of tokens per chunk: \n",
      "247.0\n",
      "No of char in chunk: \n",
      "998\n",
      "No of words in chunk: \n",
      "101\n",
      "Approx no of tokens per chunk: \n",
      "249.5\n",
      "No of char in chunk: \n",
      "133\n",
      "No of words in chunk: \n",
      "15\n",
      "Approx no of tokens per chunk: \n",
      "33.25\n",
      "No of char in chunk: \n",
      "999\n",
      "No of words in chunk: \n",
      "147\n",
      "Approx no of tokens per chunk: \n",
      "249.75\n",
      "No of char in chunk: \n",
      "802\n",
      "No of words in chunk: \n",
      "122\n",
      "Approx no of tokens per chunk: \n",
      "200.5\n",
      "No of char in chunk: \n",
      "314\n",
      "No of words in chunk: \n",
      "47\n",
      "Approx no of tokens per chunk: \n",
      "78.5\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(docs)):\n",
    "    print(\"No of char in chunk: \")\n",
    "    print(len(docs[i].page_content))\n",
    "    print(\"No of words in chunk: \")\n",
    "    print(len(docs[i].page_content.split(\" \")))\n",
    "    print(\"Approx no of tokens per chunk: \")\n",
    "    print(len(docs[i].page_content)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9565025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#form a dictionary from the docs storing page content and metadata\n",
    "content_dict =[]\n",
    "for i in range(len(docs)):\n",
    "    content_dict.append({\n",
    "        \"page_content\": docs[i].page_content,\n",
    "        \"metadata\": docs[i].metadata ,\n",
    "        \"number_of_char\": len(docs[i].page_content),\n",
    "        \"number of words\": len(docs[i].page_content.split(\" \")),\n",
    "        \"number of tokens\": len(docs[i].page_content)/4\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6334af55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_content': 'WORK EXPERIENCE Software Engineer Intern F5 Networks\\n\\nFALLON WINSLOW Software Engineer Intern\\n\\n2023 - current\\n\\nSeattle, WA Implemented a new authentication module in Python, improving system security compliance and saving an estimated $2,046 on potential breach risks Upgraded the Jenkins pipeline for continuous integration, speeding up code deployment times by three hours Developed a MySQL database schema design, improving data integrity and access speed by 39% Designed a user-friendly interface for our internal tool using Django, which increased user adoption by an extra 329 users within the ﬁrst week alone\\n\\nf.winslow@email.com (123) 456-7890 Seattle, WA LinkedIn\\n\\nEDUCATION Bachelor of Science Computer Science University of Washington\\n\\nPROJECTS CodeIt Team Member\\n\\n2019 - 2023 Seattle, WA\\n\\n2022',\n",
       "  'metadata': {'source': 'C:\\\\Users\\\\chnn2\\\\resumeShortlisting\\\\files\\\\resume1.pdf'},\n",
       "  'number_of_char': 805,\n",
       "  'number of words': 107,\n",
       "  'number of tokens': 201.25},\n",
       " {'page_content': 'PROJECTS CodeIt Team Member\\n\\n2019 - 2023 Seattle, WA\\n\\n2022\\n\\nSupervised the integration of user feedback into project iterations, enhancing usability scores by 2 points on a scale of 0 to 10 Created a dynamic and responsive web UI with Visual Studio Code, resulting in a signiﬁcant increase of 158 new users within the ﬁrst day of launch alone Formulated strategies for database optimization in MySQL, which reduced query response times from an average of 12 seconds to 4.8 seconds Expanded the application’s functionality by incorporating Python scripts for data analysis, increasing data processing capacities by 2.7 GB per day\\n\\nSKILLS\\n\\nVisual Studio Code Git Python Django MySQL OpenShift IBM Cloud Jenkins\\n\\nCyberGuard Workshop Workshop Attendee\\n\\n2021',\n",
       "  'metadata': {'source': 'C:\\\\Users\\\\chnn2\\\\resumeShortlisting\\\\files\\\\resume1.pdf'},\n",
       "  'number_of_char': 753,\n",
       "  'number of words': 110,\n",
       "  'number of tokens': 188.25},\n",
       " {'page_content': 'CyberGuard Workshop Workshop Attendee\\n\\n2021\\n\\nEngaged in a session focused on ethical hacking, learning to use Git for version control to manage and maintain security scripts and tools Built a basic threat simulation model, which augmented my ability to set up secure environments for applications deployed using Jenkins pipelines Introduced to the principles of secure coding practices, employing Visual Studio Code for scanning and ﬁxing over 19 vulnerabilities in the codebase Acquired knowledge on building a basic threat simulation model, introducing me to the secure setup of CI/CD pipelines using Jenkins',\n",
       "  'metadata': {'source': 'C:\\\\Users\\\\chnn2\\\\resumeShortlisting\\\\files\\\\resume1.pdf'},\n",
       "  'number_of_char': 610,\n",
       "  'number of words': 89,\n",
       "  'number of tokens': 152.5},\n",
       " {'page_content': 'CYNTHIA DWAYNE\\n\\nSoftware Developer\\n\\nCONTACT\\n\\nWORK EXPERIENCE Software Developer QuickBooks January 2017 - current / New York, NY\\n\\ncynthia@beamjobs.com (123) 456-7890 Brooklyn, NY LinkedIn Github\\n\\nWorked on the payments team to save time and improve cash ﬂow for over 50,000 through the development of modern, responsive customer experiences\\n\\nLed the migration from AWS to GCP for the team to reduce · Worked closely with the product team to re-conﬁgure the\\n\\nCAREER OBJECTIVE Throughout my 7-year-plus career as a software developer, I have focused on developing scalable and well-documented code. I enjoy working collaboratively but can also run with projects independently. Excited about the prospect of joining a product-driven company like Acme Corp.\\n\\ncloud costs by $260,000 per year\\n\\nprocessing of invoices, saving customers over 125,000 manual hours of work per month\\n\\nMentored 3 junior front-end developers on the team on React,\\n\\nand documented best practices within the organization',\n",
       "  'metadata': {'source': 'C:\\\\Users\\\\chnn2\\\\resumeShortlisting\\\\files\\\\resume2.pdf'},\n",
       "  'number_of_char': 990,\n",
       "  'number of words': 137,\n",
       "  'number of tokens': 247.5},\n",
       " {'page_content': 'and documented best practices within the organization\\n\\nFront-End Developer AMR January 2014 - December 2016 / New York, NY\\n\\nContributed to the in-house UI library to create reusable · Created a web app MVP for a store delivery management\\n\\ncomponents that saved 125+ hours of development per month\\n\\nEDUCATION Bachelor of Science Computer Science University of Delaware August 2008 - May 2012 Newark, DE\\n\\nplatform with 200+ business customers to create, manage, and monitor deliveries using React and Redux\\n\\nAdded features to meditation app with 5,000+ monthly users, enabling audio and video uploads using React and Redux · Improved customer conversion rate by 17% through A/B testing of diﬀerent components and combinations, representing $500,000+ in incremental annual revenue\\n\\nSKILLS Python (Django) SQL (PostgreSQL, MySQL) Cloud (GCP, AWS) JavaScript (ES6, React, Redux, Node.js) Typescript HTML/ CSS CI/CD\\n\\nHelp Desk Analyst Kelly June 2012 - January 2014 / New York, NY',\n",
       "  'metadata': {'source': 'C:\\\\Users\\\\chnn2\\\\resumeShortlisting\\\\files\\\\resume2.pdf'},\n",
       "  'number_of_char': 974,\n",
       "  'number of words': 141,\n",
       "  'number of tokens': 243.5},\n",
       " {'page_content': 'Help Desk Analyst Kelly June 2012 - January 2014 / New York, NY\\n\\nDiagnosed technical issues for 30+ clients per day by phone, email, and chat, solving issues within 15 minutes on average · Successfully reached solutions for 92% of computer errors, and escalated more complex tickets to higher tiers to assist clients as quickly as possible\\n\\nCreated user accounts for 50+ clients per week, and assisted · Created and updated documentation as needed concerning\\n\\nthem with setting up and customizing their accounts\\n\\nnetwork, software, and hardware problems',\n",
       "  'metadata': {'source': 'C:\\\\Users\\\\chnn2\\\\resumeShortlisting\\\\files\\\\resume2.pdf'},\n",
       "  'number_of_char': 553,\n",
       "  'number of words': 84,\n",
       "  'number of tokens': 138.25},\n",
       " {'page_content': \"CAREER OBJECTIVE\\n\\nCAIUS KESSLER\\n\\nHighly-driven computer science student with growing knowledge in Bitbucket, Oracle, and Java, seeking a software engineering internship at Microsoft. As a Microsoft Certiﬁed: Azure Developer Associate, I'm ready to contribute my passion and skills to help drive innovation as a global technology leader.\\n\\nSoftware Engineer Intern\\n\\nckessler@email.com\\n\\n(123) 456-7890\\n\\nSeattle, WA\\n\\nWORK EXPERIENCE\\n\\nLinkedIn\\n\\nData Entry Specialist Expedia Group\\n\\nMay 2021 - current\\n\\nSeattle, WA\\n\\nEDUCATION\\n\\nProcessed and entered 1,200+ travel records per week into Oracle databases.\\n\\nB.S.\\n\\nComputer Science\\n\\nUtilized Java-based tools to import and export data, reducing data transfer time by 34%.\\n\\nUniversity of Washington\\n\\nDeveloped and deployed a Django-based web interface, increasing data accessibility for remote team by 22%.\\n\\nSeptember 2020 - current\\n\\nSeattle, WA\\n\\nGenerated data-driven insights, supporting key business decisions and driving a 6% increase in revenue.\",\n",
       "  'metadata': {'source': 'C:\\\\Users\\\\chnn2\\\\resumeShortlisting\\\\files\\\\resume3.pdf'},\n",
       "  'number_of_char': 988,\n",
       "  'number of words': 115,\n",
       "  'number of tokens': 247.0},\n",
       " {'page_content': 'Relevant courses\\n\\nComputer Science I and II\\n\\nGathered monthly reports on data entry metrics, helping strategic planning and resource allocation.\\n\\nDiscrete Mathematics\\n\\nData Structures and Algorithms\\n\\nComputer Organization and Architecture\\n\\nPROJECTS\\n\\nTech Pursuit Creator\\n\\nOperating Systems\\n\\n2020 - 2021\\n\\nSKILLS\\n\\nDesigned a robust database architecture utilizing Oracle, enhancing game performance by 38%.\\n\\nVisual Studio\\n\\nStreamlined game development process by integrating Visual Studio, reducing overall project time by 11%.\\n\\nBitbucket\\n\\nOracle\\n\\nImplemented version control and collaboration using Bitbucket, leading to a 21% decrease in code conﬂicts.\\n\\nDjango\\n\\nWindows\\n\\nEnhanced game character AI using Java, increasing positive user reviews by 29%.\\n\\nJava\\n\\nConducted extensive playtesting and user feedback analysis every month, eliminating game bugs.\\n\\nHOBBIES\\n\\nFood Photography\\n\\nCERTIFICATIONS\\n\\nTravel Photography\\n\\nVideo editing and post- production\\n\\nMicrosoft Certiﬁed: Azure Developer Associate',\n",
       "  'metadata': {'source': 'C:\\\\Users\\\\chnn2\\\\resumeShortlisting\\\\files\\\\resume3.pdf'},\n",
       "  'number_of_char': 998,\n",
       "  'number of words': 101,\n",
       "  'number of tokens': 249.5},\n",
       " {'page_content': 'Video editing and post- production\\n\\nMicrosoft Certiﬁed: Azure Developer Associate\\n\\nOracle Certiﬁed Professional: Java SE 11 Developer',\n",
       "  'metadata': {'source': 'C:\\\\Users\\\\chnn2\\\\resumeShortlisting\\\\files\\\\resume3.pdf'},\n",
       "  'number_of_char': 133,\n",
       "  'number of words': 15,\n",
       "  'number of tokens': 33.25},\n",
       " {'page_content': 'C H A R L E S MC T U R L A N D\\n\\nSOFTWARE ENGINEER\\n\\nCONTACT\\n\\nWORK EXPERIENCE Software Engineer Embark January 2015 - current / New York, NY\\n\\ncmcturland@email.com (123) 456-7890 New York, NY\\n\\nLinkedIn\\n\\nWorked with product managers to re-architect a multi-page web app into a single page web-app, boosting yearly revenue by $1.4M Constructed the logic for a streamlined ad-serving platform that scaled to our 35M users, which improved the page speed by 15% after implementation Tested software for bugs and operating speed, ﬁxing bugs and documenting processes to increase efﬁciency by 18% Iterated platform for college admissions, collaborating with a group of 4 engineers to create features across the software\\n\\nEDUCATION B.S. Computer Science University of Pittsburgh September 2008 - April 2012 Pittsburgh, PA\\n\\nSoftware Engineer MarketSmart April 2012 - January 2015 / Washington, DC\\n\\nSKILLS Python (Django) Javascript (NodeJS ReactJS, jQuery) SQL (MySQL, PostgreSQL, NoSQL) HTML5/CSS AWS Unix, Git',\n",
       "  'metadata': {'source': 'C:\\\\Users\\\\chnn2\\\\resumeShortlisting\\\\files\\\\resume4.pdf'},\n",
       "  'number_of_char': 999,\n",
       "  'number of words': 147,\n",
       "  'number of tokens': 249.75},\n",
       " {'page_content': 'Built RESTful APIs that served data to the JavaScript front-end based on dynamically chosen user inputs that handled over 500,000 concurrent users Built internal tool using NodeJS and Pupeteer.js to automate QA and monitoring of donor-facing web app, which improved CTR by 3% Reviewed code and conducted testing for 3 additional features on donor-facing web app that increased contributions by 12%\\n\\nSoftware Engineer Intern Marketing Science Company April 2011 - March 2012 / Pittsburgh, PA\\n\\nPartnered with a developer to implement RESTful APIs in Django, enabling analytics team to increase reporting speed by 24% Using Selenium I built out a unit testing infrastructure for a client application that reduced the number of bugs reported by the client by 11% month over month\\n\\nPROJECTS Poker Simulation',\n",
       "  'metadata': {'source': 'C:\\\\Users\\\\chnn2\\\\resumeShortlisting\\\\files\\\\resume4.pdf'},\n",
       "  'number_of_char': 802,\n",
       "  'number of words': 122,\n",
       "  'number of tokens': 200.5},\n",
       " {'page_content': 'PROJECTS Poker Simulation\\n\\nBuilt a full-stack web app to allow users to simulate and visualize outcomes of poker hands against opponents of different play styles using open source cards.js on the front-end Utilized sci-kit learn in Python to simulate possible outcomes under different scenarios that the user chose',\n",
       "  'metadata': {'source': 'C:\\\\Users\\\\chnn2\\\\resumeShortlisting\\\\files\\\\resume4.pdf'},\n",
       "  'number_of_char': 314,\n",
       "  'number of words': 47,\n",
       "  'number of tokens': 78.5}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53727743",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1858bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8eba291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chnn2\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "embedding_model= SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94724c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(content_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac759baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_content</th>\n",
       "      <th>metadata</th>\n",
       "      <th>number_of_char</th>\n",
       "      <th>number of words</th>\n",
       "      <th>number of tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WORK EXPERIENCE Software Engineer Intern F5 Ne...</td>\n",
       "      <td>{'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...</td>\n",
       "      <td>805</td>\n",
       "      <td>107</td>\n",
       "      <td>201.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROJECTS CodeIt Team Member\\n\\n2019 - 2023 Sea...</td>\n",
       "      <td>{'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...</td>\n",
       "      <td>753</td>\n",
       "      <td>110</td>\n",
       "      <td>188.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CyberGuard Workshop Workshop Attendee\\n\\n2021\\...</td>\n",
       "      <td>{'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...</td>\n",
       "      <td>610</td>\n",
       "      <td>89</td>\n",
       "      <td>152.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CYNTHIA DWAYNE\\n\\nSoftware Developer\\n\\nCONTAC...</td>\n",
       "      <td>{'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...</td>\n",
       "      <td>990</td>\n",
       "      <td>137</td>\n",
       "      <td>247.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and documented best practices within the organ...</td>\n",
       "      <td>{'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...</td>\n",
       "      <td>974</td>\n",
       "      <td>141</td>\n",
       "      <td>243.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Help Desk Analyst Kelly June 2012 - January 20...</td>\n",
       "      <td>{'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...</td>\n",
       "      <td>553</td>\n",
       "      <td>84</td>\n",
       "      <td>138.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAREER OBJECTIVE\\n\\nCAIUS KESSLER\\n\\nHighly-dr...</td>\n",
       "      <td>{'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...</td>\n",
       "      <td>988</td>\n",
       "      <td>115</td>\n",
       "      <td>247.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Relevant courses\\n\\nComputer Science I and II\\...</td>\n",
       "      <td>{'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...</td>\n",
       "      <td>998</td>\n",
       "      <td>101</td>\n",
       "      <td>249.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Video editing and post- production\\n\\nMicrosof...</td>\n",
       "      <td>{'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...</td>\n",
       "      <td>133</td>\n",
       "      <td>15</td>\n",
       "      <td>33.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C H A R L E S MC T U R L A N D\\n\\nSOFTWARE ENG...</td>\n",
       "      <td>{'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...</td>\n",
       "      <td>999</td>\n",
       "      <td>147</td>\n",
       "      <td>249.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Built RESTful APIs that served data to the Jav...</td>\n",
       "      <td>{'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...</td>\n",
       "      <td>802</td>\n",
       "      <td>122</td>\n",
       "      <td>200.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PROJECTS Poker Simulation\\n\\nBuilt a full-stac...</td>\n",
       "      <td>{'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...</td>\n",
       "      <td>314</td>\n",
       "      <td>47</td>\n",
       "      <td>78.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         page_content  \\\n",
       "0   WORK EXPERIENCE Software Engineer Intern F5 Ne...   \n",
       "1   PROJECTS CodeIt Team Member\\n\\n2019 - 2023 Sea...   \n",
       "2   CyberGuard Workshop Workshop Attendee\\n\\n2021\\...   \n",
       "3   CYNTHIA DWAYNE\\n\\nSoftware Developer\\n\\nCONTAC...   \n",
       "4   and documented best practices within the organ...   \n",
       "5   Help Desk Analyst Kelly June 2012 - January 20...   \n",
       "6   CAREER OBJECTIVE\\n\\nCAIUS KESSLER\\n\\nHighly-dr...   \n",
       "7   Relevant courses\\n\\nComputer Science I and II\\...   \n",
       "8   Video editing and post- production\\n\\nMicrosof...   \n",
       "9   C H A R L E S MC T U R L A N D\\n\\nSOFTWARE ENG...   \n",
       "10  Built RESTful APIs that served data to the Jav...   \n",
       "11  PROJECTS Poker Simulation\\n\\nBuilt a full-stac...   \n",
       "\n",
       "                                             metadata  number_of_char  \\\n",
       "0   {'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...             805   \n",
       "1   {'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...             753   \n",
       "2   {'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...             610   \n",
       "3   {'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...             990   \n",
       "4   {'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...             974   \n",
       "5   {'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...             553   \n",
       "6   {'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...             988   \n",
       "7   {'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...             998   \n",
       "8   {'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...             133   \n",
       "9   {'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...             999   \n",
       "10  {'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...             802   \n",
       "11  {'source': 'C:\\Users\\chnn2\\resumeShortlisting\\...             314   \n",
       "\n",
       "    number of words  number of tokens  \n",
       "0               107            201.25  \n",
       "1               110            188.25  \n",
       "2                89            152.50  \n",
       "3               137            247.50  \n",
       "4               141            243.50  \n",
       "5                84            138.25  \n",
       "6               115            247.00  \n",
       "7               101            249.50  \n",
       "8                15             33.25  \n",
       "9               147            249.75  \n",
       "10              122            200.50  \n",
       "11               47             78.50  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7f1760",
   "metadata": {},
   "source": [
    "## Storing the vectors into chroma  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fbb7cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18b875af",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55d0a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(documents=docs,embedding=embedding_model,persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cdd300",
   "metadata": {},
   "source": [
    "## Retriving the relevant documents to the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abc63750",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_retriever = db.as_retriever(\n",
    "    search_type =\"mmr\",\n",
    "    search_kwargs={\"k\":2,\"fetch_k\":5})\n",
    "#fetch_k ki value by default 20 hoti h use it when no of documents is higher\n",
    "\n",
    "#i am thinking that value of k should be taken input from users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5348fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query= \"Which candidates is suitable for data science role.Give me names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f9cc846",
   "metadata": {},
   "outputs": [],
   "source": [
    "output= query_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1041906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAREER OBJECTIVE\n",
      "\n",
      "CAIUS KESSLER\n",
      "\n",
      "Highly-driven computer science student with growing knowledge in Bitbucket, Oracle, and Java, seeking a software engineering internship at Microsoft. As a Microsoft Certiﬁed: Azure Developer Associate, I'm ready to contribute my passion and skills to help drive innovation as a global technology leader.\n",
      "\n",
      "Software Engineer Intern\n",
      "\n",
      "ckessler@email.com\n",
      "\n",
      "(123) 456-7890\n",
      "\n",
      "Seattle, WA\n",
      "\n",
      "WORK EXPERIENCE\n",
      "\n",
      "LinkedIn\n",
      "\n",
      "Data Entry Specialist Expedia Group\n",
      "\n",
      "May 2021 - current\n",
      "\n",
      "Seattle, WA\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "Processed and entered 1,200+ travel records per week into Oracle databases.\n",
      "\n",
      "B.S.\n",
      "\n",
      "Computer Science\n",
      "\n",
      "Utilized Java-based tools to import and export data, reducing data transfer time by 34%.\n",
      "\n",
      "University of Washington\n",
      "\n",
      "Developed and deployed a Django-based web interface, increasing data accessibility for remote team by 22%.\n",
      "\n",
      "September 2020 - current\n",
      "\n",
      "Seattle, WA\n",
      "\n",
      "Generated data-driven insights, supporting key business decisions and driving a 6% increase in revenue.\n",
      "C:\\Users\\chnn2\\resumeShortlisting\\files\\resume3.pdf\n",
      "Relevant courses\n",
      "\n",
      "Computer Science I and II\n",
      "\n",
      "Gathered monthly reports on data entry metrics, helping strategic planning and resource allocation.\n",
      "\n",
      "Discrete Mathematics\n",
      "\n",
      "Data Structures and Algorithms\n",
      "\n",
      "Computer Organization and Architecture\n",
      "\n",
      "PROJECTS\n",
      "\n",
      "Tech Pursuit Creator\n",
      "\n",
      "Operating Systems\n",
      "\n",
      "2020 - 2021\n",
      "\n",
      "SKILLS\n",
      "\n",
      "Designed a robust database architecture utilizing Oracle, enhancing game performance by 38%.\n",
      "\n",
      "Visual Studio\n",
      "\n",
      "Streamlined game development process by integrating Visual Studio, reducing overall project time by 11%.\n",
      "\n",
      "Bitbucket\n",
      "\n",
      "Oracle\n",
      "\n",
      "Implemented version control and collaboration using Bitbucket, leading to a 21% decrease in code conﬂicts.\n",
      "\n",
      "Django\n",
      "\n",
      "Windows\n",
      "\n",
      "Enhanced game character AI using Java, increasing positive user reviews by 29%.\n",
      "\n",
      "Java\n",
      "\n",
      "Conducted extensive playtesting and user feedback analysis every month, eliminating game bugs.\n",
      "\n",
      "HOBBIES\n",
      "\n",
      "Food Photography\n",
      "\n",
      "CERTIFICATIONS\n",
      "\n",
      "Travel Photography\n",
      "\n",
      "Video editing and post- production\n",
      "\n",
      "Microsoft Certiﬁed: Azure Developer Associate\n",
      "C:\\Users\\chnn2\\resumeShortlisting\\files\\resume3.pdf\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(output)):\n",
    "    print(output[i].page_content)\n",
    "    print(output[i].metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d41c9e",
   "metadata": {},
   "source": [
    "## Generation part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7172df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#watsonx_api_key : \"cpd-apikey-IBMid-693000FXDF-2024-07-07T06:52:44Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "watsonx_api_key = getpass()\n",
    "os.environ[\"WATSONX_APIKEY\"] = watsonx_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e717364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist the vectors generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31124203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ibm import ChatWatsonx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2190cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"decoding_method\": \"sample\",\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"min_new_tokens\": 1,\n",
    "    \"stop_sequences\": [\".\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e3ca6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#project_id : 1e8dd3eb-75ed-42e5-ba89-eefc86f646dd\n",
    "#location: https://us-south.ml.cloud.ibm.com\n",
    "llm_chat = ChatWatsonx(\n",
    "    model_id=\"ibm/granite-13b-chat-v2\",\n",
    "    url=\"https://eu-de.ml.cloud.ibm.com\",\n",
    "    project_id=\"8df2d8b2-f482-4d75-8f43-8c2143157922\",\n",
    "    params=parameters,\n",
    "    apikey=\"SQWPrDi9MMaaTIeyRA6kEDAICy4g2pX5YFMb7eOftswx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e459c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0238dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm_chat, \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=query_retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70390eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Know the sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a716376",
   "metadata": {},
   "source": [
    "### Creating a prompt containing warning + some job descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bebf2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "warning = \"If you don't know the answer, just say that you don't know the answer and say if you can help you in anything, don't try to make up an answer.If the source of matching results are similar,then just give one as output.\"\n",
    "job_description = \"Engineering in computer science or a related technical field,A fresher or having some work experience. Good sense of product with a focus on shipping user-facing data-driven features, Expertise in Python and Python based ML/DL and Data Science frameworks. \\\n",
    "Excellent coding, analysis, and problem-solving skills. Proven knowledge of data structure and algorithms. \\\n",
    "Experience with various database systems such as MySQL,MongoDB.\\\n",
    "Have project related to Data science role.\\\n",
    "Strong communication and collaboration skills\"\n",
    "question = warning+job_description + \" Based on the given job description\"\n",
    "query = question + \"short list resumes which is good fit based on skills,education and work experience mentioned in it? also provide the candidate name which will be mentioned in pdf without subheading\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55c785f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = qa_chain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21774b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given job descriptions and the skill sets required, here are two candidates that may be a good fit:\n",
      "\n",
      "1.\n",
      "\n",
      "\n",
      "Sources:\n",
      "C:\\Users\\chnn2\\resumeShortlisting\\files\\resume3.pdf\n",
      "C:\\Users\\chnn2\\resumeShortlisting\\files\\resume4.pdf\n"
     ]
    }
   ],
   "source": [
    "process_llm_response(llm_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
